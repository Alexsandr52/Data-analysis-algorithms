{"cells":[{"cell_type":"markdown","metadata":{"id":"Kw01g10zBjZr"},"source":["## Урок 1. Алгоритм линейной регрессии. Градиентный спуск"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"ak8b3KV45kVW"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"i77tZbAd5plB","outputId":"784cb9ea-d0b1-4633-8ded-80edaa795b76"},"outputs":[{"data":{"text/plain":["array([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n","       [ 1,  1,  2,  5,  3,  0,  5, 10,  1,  2]])"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","              [1, 1, 2, 5, 3, 0, 5, 10, 1, 2]])\n","X"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"VsNrKi1Q6Wmh"},"outputs":[],"source":["y = [45, 55, 50, 55, 60, 35, 75, 80, 50, 60]"]},{"cell_type":"markdown","metadata":{"id":"QqGEYJDNBjaP"},"source":["### Практическое задание"]},{"cell_type":"markdown","metadata":{"id":"huXrhXQsZTMt"},"source":["1. Подберите скорость обучения (alpha) и количество итераций."]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185},"id":"IDB22MQKMYaJ","outputId":"4c03219e-a57c-4583-f439-6699fd0619bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of objects = 10        \n","Learning rate = 0.01        \n","Initial weights = [1.  0.5] \n","\n","Iteration #0: W_new = [2.08 4.27], MSE = 3047.75\n","Iteration #100: W_new = [28.38281518  6.83710367], MSE = 177.43\n","Iteration #200: W_new = [38.38986469  5.02247953], MSE = 65.33\n","Iteration #300: W_new = [42.39314129  4.29654705], MSE = 47.39\n","Iteration #400: W_new = [43.99463466  4.00614091], MSE = 44.52\n","Iteration #500: W_new = [44.63530512  3.8899652 ], MSE = 44.06\n","Iteration #600: W_new = [44.89160255  3.84348962], MSE = 43.98\n","Iteration #700: W_new = [44.99413322  3.82489726], MSE = 43.97\n","Iteration #800: W_new = [45.03515017  3.81745947], MSE = 43.97\n","Iteration #900: W_new = [45.05155882  3.81448401], MSE = 43.97\n"]}],"source":["n = X.shape[1]\n","alpha = 1e-2\n","W = np.array([1, 0.5])\n","print(f'Number of objects = {n} \\\n","       \\nLearning rate = {alpha} \\\n","       \\nInitial weights = {W} \\n')\n","\n","# увеличил количество итераций до 1000\n","# можно было увеличить до 700 так как после 700 итераций mse почти не изменяется\n","for i in range(1000):\n","    y_pred = np.dot(W, X)\n","    err = calc_mse(y, y_pred)\n","    for k in range(W.shape[0]):\n","        W[k] -= alpha * (1/n * 2 * np.sum(X[k] * (y_pred - y)))\n","    # if i % 10 == 0:\n","        # не уменьшаем alpha на каждом 10 шаге\n","        # alpha /= 1.1\n","    if i % 100 == 0:\n","        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"]},{"cell_type":"markdown","metadata":{"id":"dNd19yVmBjaR"},"source":["*3. Вместо того чтобы задавать количество итераций, задайте условие остановки алгоритма, когда ошибка за итерацию начинает изменяться ниже определённого порога — упрощённый аналог параметра tol в линейной регрессии в sklearn."]},{"cell_type":"code","execution_count":35,"metadata":{"collapsed":true,"id":"VjV39BwKBjaR"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of objects = 10        \n","Learning rate = 0.01        \n","Initial weights = [1.  0.5] \n","\n","Iteration #100: W_new = [28.38281518  6.83710367], MSE = 179.9\n","Iteration #200: W_new = [38.38986469  5.02247953], MSE = 65.72\n","Iteration #300: W_new = [42.39314129  4.29654705], MSE = 47.45\n","Iteration #400: W_new = [43.99463466  4.00614091], MSE = 44.53\n","Iteration #500: W_new = [44.63530512  3.8899652 ], MSE = 44.06\n","Iteration #600: W_new = [44.89160255  3.84348962], MSE = 43.98\n","Iteration #700: W_new = [44.99413322  3.82489726], MSE = 43.97\n","Iteration #779: W_new = [45.02934785  3.81851163], MSE = 43.97, MSE differense = -9.929908429739953e-06\n"]}],"source":["n = X.shape[1]\n","alpha = 1e-2\n","W = np.array([1, 0.5])\n","mse_points = [1]\n","print(f'Number of objects = {n} \\\n","       \\nLearning rate = {alpha} \\\n","       \\nInitial weights = {W} \\n')\n","\n","for i in range(1000):\n","    y_pred = np.dot(W, X)\n","    mse_points.append(calc_mse(y, y_pred))\n","\n","    for k in range(W.shape[0]):\n","        W[k] -= alpha * (1/n * 2 * np.sum(X[k] * (y_pred - y)))\n","\n","    if i % 100 == 0 and i != 0:\n","        print(f'Iteration #{i}: W_new = {W}, MSE = {round(mse_points[i],2)}')\n","    if abs(mse_points[i] - mse_points[i-1]) < 1e-5:\n","        print(f'Iteration #{i}: W_new = {W}, MSE = {round(mse_points[i],2)}, MSE differense = {mse_points[i] - mse_points[i-1]}')\n","        break"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Lesson_1_script.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"50292dbb1f747f7151d445135d392af3138fb3c65386d17d9510cb605222b10b"}}},"nbformat":4,"nbformat_minor":0}
